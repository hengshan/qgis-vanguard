import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)


import sys
import os

sys.path.append(r'C:\Program Files\QGIS 3.20.3\apps\qgis\python') #this is important for loading qgis library
sys.path.append(r'C:\Program Files\QGIS 3.20.3\apps\qgis\python\plugins') #this is important for loading processing library


import qgis
from qgis.gui import *
from qgis.core import *
from qgis.utils import plugins
from PyQt5.QtCore import *
from qgis.analysis import QgsNativeAlgorithms


get_ipython().run_line_magic("matplotlib", " inline")

from pysal.lib import weights
from pysal.lib import cg as geometry
import contextily
import geopandas as gpd
import seaborn as sb
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from shapely.geometry import Polygon


from pysal.model import spreg
from pysal.explore import esda
from scipy import stats
import statsmodels.api as sm
from statsmodels.stats.weightstats import ttest_ind
from statsmodels.formula.api import ols
from sklearn.linear_model import LinearRegression
import sklearn.metrics as metrics
from sklearn.model_selection import train_test_split


list1=[1,2,3]
(1+2+3)/3

1*1/4+2*1/2+1*1/4
E(X) = 0


fig = plt.figure()
 
plt.xlim(-7, 7)
plt.ylim(0, 7)

X2 = np.linspace(-5, 5, 50)
Y2 = X2 +1
plt.plot(X2, Y2, color='green', linestyle='--', label=r'$y=x+1$')
 
ax = plt.gca()
ax.spines['top'].set_color('none')
ax.spines['right'].set_color('none')
ax.spines['left'].set_position(('data', 0))

plt.xticks(np.linspace(-5, 5, 11))
plt.arrow(0, 7, 0, 0, width=0.2, color="k", clip_on=False, head_width=0.2, head_length=0.2)
plt.arrow(7, 0, 0.01, 0, width=0.2, color="k", clip_on=False, head_width=0.2, head_length=0.2)
plt.legend()
plt.show()


x = np.linspace(-5,5,100)
e = np.random.normal(0,1,size = 100)
y = x +1 + e
plt.axis('equal')
plt.gca().set_xlim(-5, 5)
plt.plot(x, y, ".k")


x = np.linspace(-5,5,100)
e = np.random.normal(0,1,size = 100)
y = x +1 + e
plt.axis('equal')
plt.gca().set_xlim(-5, 5)
plt.plot(x, y, ".k")


x = np.linspace(-5,5,100)
e = np.random.normal(0,1,size = 100)
a = 1 + np.random.normal(0,2,size = 100)
# a = 1
y = a*x +1 + e
plt.axis('equal')
plt.gca().set_xlim(-5, 5)
plt.plot(x, y, ".k")


dataset = pd.read_csv('Data/weight-height.csv')
dataset.head()


dataset_sample = dataset.groupby('Gender').sample(n=20)
dataset_sample


genders=["Female", "Male"]
dummy_vars=[1,0]
dataset_sample['Gender_N'] = dataset_sample['Gender'].replace(genders, dummy_vars)


dataset_sample


fig,axs = plt.subplots(1,3,figsize=(12,6))

sb.regplot(x='Weight', y='Height', data=dataset_sample,ax=axs[0])

sb.boxplot(x='Gender', y='Height', data=dataset_sample, color='#99c2a2',ax=axs[1])
sb.swarmplot(x="Gender", y="Height", data=dataset_sample, color='#7d0013',ax=axs[1])

sb.regplot(x="Height", y="Gender_N", data=dataset_sample,y_jitter=.02, logistic=True,ax=axs[2])
plt.show()


sb.lmplot(x='Weight', y='Height', hue="Gender",data=dataset_sample)


X = dataset.iloc[:,1].values  #independent variable array
y = dataset.iloc[:,2].values  #dependent variable vector


X


y


X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=1/4,random_state=0)


regressor = LinearRegression()

regressor.fit(X_train.reshape(-1, 1),y_train) #actually produces the linear eqn for the data


y_test_pred = regressor.predict(X_test.reshape(-1,1)) 
y_test_pred


y_test


#plot for the TRAIN
plt.scatter(X_train, y_train, color='red',s =.1) # plotting the observation line
plt.plot(X_train, regressor.predict(X_train.reshape(-1,1)), color='blue') # plotting the regression line
plt.title("Height vs Weight (Training set)") # stating the title of the graph
plt.xlabel("Height (inches)") # adding the name of x-axis
plt.ylabel("Weight (lbs)") # adding the name of y-axis
plt.show() # specifies end of graph


#plot for the TEST
plt.scatter(X_test, y_test, color='red', s=.1) 
plt.plot(X_test, y_test_pred, color='blue') # plotting the regression line

plt.title("Height vs Weight (Testing set)") # stating the title of the graph
plt.xlabel("Height (inches)") # adding the name of x-axis
plt.ylabel("Weight (lbs)") # adding the name of y-axis
plt.show() # specifies end of graph


def regression_results(y_true, y_pred):
    # Regression metrics
    explained_variance=metrics.explained_variance_score(y_true, y_pred)
    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) 
    mse=metrics.mean_squared_error(y_true, y_pred) 
    mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)
    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)
    r2=metrics.r2_score(y_true, y_pred)

    print('explained_variance: ', round(explained_variance,4))    
    print('mean_squared_log_error: ', round(mean_squared_log_error,4))
    print('r2: ', round(r2,4))
    print('MAE: ', round(mean_absolute_error,4))
    print('MSE: ', round(mse,4))
    print('RMSE: ', round(np.sqrt(mse),4))


regression_results(y_test,y_test_pred)


regression_results(y_train, regressor.predict(X_train.reshape(-1,1)))


dataset_dummies = pd.get_dummies(dataset.Gender, prefix='Gender').drop('Gender_Male', axis=1)
dataset_dummies.head()

# Take our numeric features and our output label
dataset_features = dataset[['Height', 'Weight']]

# Combine into one dataframe
df = pd.concat([dataset_dummies,dataset_features], axis=1)
df.head()


# another of adding the dummies 
# dataset['Gender_Female'] = (dataset.Gender == 'Female').astype(int)
# dataset.head()


X = df.iloc[:,[0,2]].values  #independent variable array
y = df.iloc[:,1].values  #dependent variable vector
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=1/4,random_state=0)
regressor = LinearRegression()
regressor.fit(X_train,y_train) #actually produces the linear eqn for the data
y_test_pred = regressor.predict(X_test) 
y_test_pred
regression_results(y_test,y_test_pred)


# regression R2 score of train data
regressor.score(X_train, y_train)


X = df.iloc[:,[0,2]]  #independent variable array
y = df.iloc[:,1]#dependent variable vector


X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=1/4,random_state=0)


X_train_ = sm.add_constant(X_train)


model = sm.OLS(y_train,X_train_).fit()


model.params


(model.summary())


# the population data indicates that male is taller and heavier than female.  
dataset.groupby('Gender').mean()


# if we only sample 40 data records (20 female and 20 maile), the sample mean of male is larger than the sample female. 
sample_dataset1 = dataset.groupby('Gender').apply(lambda x: x.sample(n=20))


sample_dataset1.reset_index(drop=True, inplace=True)


sample_dataset1.groupby('Gender').mean()


# Is it possible that some research teams just sampled 20 females and 20 males, and females on average are taller than men?
dataset.sort_values('Height').groupby('Gender').apply(lambda x: x.tail(20) if x.name=="Female" else x.head(20))


# we can sample again, and each time the result is different
sample_dataset2 = dataset.groupby('Gender').apply(lambda x: x.sample(n=20))


sample_dataset2.reset_index(drop=True, inplace=True)


sample_dataset2.groupby('Gender').mean()


samples_1000 = [dataset.groupby('Gender').apply(lambda x: x.sample(n=20)).assign(SampleID=i+1) for i in range(0 ,1000)]
samples = pd.concat(samples_1000)
samples.reset_index(drop=True, inplace=True)
samples


dist=samples.groupby(['SampleID','Gender']).mean().reset_index()


g=sb.histplot(data=dist, x="Height",bins=50, kde=True,hue="Gender")
g


samples_1000[200].query('Gender == "Female"').filter(items='Height').values


x1=samples_1000[200].reset_index(drop=True).query('Gender == "Female"')['Height']
x2=samples_1000[200].reset_index(drop=True).query('Gender == "Male"')['Height']


g=sb.histplot(data=dist, x="Height",bins=50, kde=True,hue="Gender")
ax = g.axes
ax.axvline(x1.mean(), ls='--',color='r')
ax.axvline(x2.mean(), ls='--',color='r')


dist


# normalize the data
dist['z_height'] = (dist['Height'] - dist['Height'].mean())/dist['Height'].std()


dist


diff=dist.query('Gender == "Female"')['z_height'].values-dist.query('Gender == "Male"')['z_height'].values


df1=pd.DataFrame({'diff':diff,'SampleID':range(1,1001)})


df1


g=sb.histplot(data=df1, x="diff",bins=50, kde=True)
ax = g.axes
ax.axvline(df1['diff'].mean(), ls='--',color='r')


s = np.random.standard_t(18, size=1000)


sb.histplot(data=s, bins=50, kde=True)


g=sb.histplot(data=df1, x="diff",bins=50, kde=True, color="b",alpha=0.5)
ax = g.axes
ax.axvline(df1['diff'].mean(), ls='--',color='r')
sb.histplot(data=s, bins=50, kde=True,ax=ax,alpha=0.5)


# return t statistics, p value, and degree of freedom
ttest_ind(x1,x2)


x_bar = np.mean(x1.values - x2.values)
mu = 0
se = np.std(x1.values - x2.values,ddof=1)/np.sqrt(len(x1.values - x2.values)-1)
t =(x_bar - mu)/se
t


stats.ttest_ind(x1, x2)


fig, axes = plt.subplots(2, 3,figsize=(25,15))
ax=axes.flatten()

# [sb.scatterplot(samples_1000[num], x="Height",y="Weight",ax=ax[i]) for i, num in enumerate(np.random.randint(0, 1000, 6))]
for i, num in enumerate(np.random.randint(0, 1000, 6)):
    sb.scatterplot(data=samples_1000[num], x="Height", y="Weight",ax=ax[i])
    sb.regplot(data=samples_1000[num], x="Height", y="Weight",ax=ax[i])


def cal_coeff(df):
    X_train_ = sm.add_constant(df['Height'])
    model = sm.OLS(df['Weight'],X_train_).fit()
    return model.params


params_1000=[cal_coeff(i) for i in samples_1000]


params_1000_df=pd.DataFrame(params_1000)


params_1000_df


intercept=1
slope=1
x_vals = np.arange(50, 80, 0.1)  
y_vals = intercept + slope * x_vals
data=pd.DataFrame({"x":x_vals,"y":y_vals})


fig, ax = plt.subplots(1, 1,figsize=(25,15))

for i, j in zip(params_1000_df['const'],params_1000_df['Height']):
    x_vals = np.arange(50, 80, 0.1)  
    y_vals = i + j * x_vals
    dt=pd.DataFrame({"x":x_vals,"y":y_vals})
    sb.lineplot(data=dt,x="x",y="y",ax=ax)


formula = 'Weight ~ Gender * Height'
# formula2 = 'Weight ~ Height'
# formula3 = 'Weight ~ Gender + Height'
# formula3 = 'Weight ~ Gender + Height + Gender:Height'
dataset = sm.add_constant(dataset)
results = ols(formula, dataset).fit()
results.summary()


hypotheses = '(Gender[T.Male]=20)'
f_test = results.t_test(hypotheses)


f_test


dataset['res'] = results.resid
dataset['pred'] = results.predict()
dataset['res_z'] = stats.zscore(dataset['res'])


dataset.dtypes


dataset.assign(Nationality = "")
dataset.loc[dataset['res_z'] > 1.5, 'Nationality'] = "Country 1"
dataset.loc[dataset['res_z'] < -1.5, 'Nationality'] = "Country 2"
dataset.loc[(dataset['res_z'] <=1.5) & (dataset['res_z'] >=-1.5), 'Nationality'] = "Country 3"


dataset


formula = 'Weight ~ Gender + Height + Nationality'
dataset = sm.add_constant(dataset)
results = ols(formula, dataset).fit()
results.summary()


sb.scatterplot(data=dataset,x="Height",y="Weight", hue="Nationality")


sb.scatterplot(data=dataset,x="Height",y="Weight", hue="Gender")


dataset.assign(X = 0,Y=0)
dataset.loc[dataset['Nationality'] == "Country 1", ['X','Y']] = [0,0]
dataset.loc[dataset['Nationality'] == "Country 2", ['X','Y']] = [100,0]
dataset.loc[dataset['Nationality'] == "Country 3", ['X','Y']] = [50,100*np.sin(np.pi/4)]


dataset_xy = dataset.groupby('Nationality').mean()
dataset_xy.reset_index(inplace=True)


dataset_xy


ax1 = dataset.plot(x="X",y="Y")
sb.scatterplot(data=dataset_xy,x='X',
                      y='Y',hue="Nationality",
                      ax=ax1, s=100)

for x,y,z in zip(dataset_xy.X,dataset_xy.Y,dataset_xy.Weight):
    label = f"Weight = {z:.2f}"
    ax1.annotate(label, # this is the text
                 (x,y), # these are the coordinates to position the label
                 textcoords="offset points", # how to position the text
                 xytext=(5,5), # distance from text to points (x,y)
                 ha='center') # horizontal alignment can be left, right or center


formula = 'Weight ~ Gender + Height + Nationality + X * Y'
dataset = sm.add_constant(dataset)
results = ols(formula, dataset).fit()
results.summary()


nsample = 50
sig = 0.5
x = np.linspace(0, 20, nsample)
X = np.column_stack((x, np.sin(x), (x-5)**2, np.ones(nsample))) # np.ones(nsample)) are constant

beta = [0.5, 0.5, -0.02, 5.]

y_true = np.dot(X, beta)
y = y_true + sig * np.random.normal(size=nsample)


x


X.shape * beta


res = sm.OLS(y, X).fit()
print(res.summary())


from statsmodels.sandbox.regression.predstd import wls_prediction_std


prstd, iv_l, iv_u = wls_prediction_std(res)

fig, ax = plt.subplots(figsize=(8,6))

ax.plot(x, y, 'o', label="data")
ax.plot(x, y_true, 'b-', label="True")
ax.plot(x, res.fittedvalues, 'r--.', label="OLS")
ax.plot(x, iv_u, 'r--')
ax.plot(x, iv_l, 'r--')
ax.legend(loc='best');


X1 = np.column_stack((x,np.ones(nsample)))
res = sm.OLS(y, X1).fit()
print(res.summary())


prstd, iv_l, iv_u = wls_prediction_std(res)

fig, ax = plt.subplots(figsize=(8,6))

ax.plot(x, y, 'o', label="data")
ax.plot(x, res.fittedvalues, 'r--.', label="OLS")
ax.plot(x, iv_u, 'r--')
ax.plot(x, iv_l, 'r--')
ax.legend(loc='best');


sz_cpf = gpd.read_file('Data/MP14_Subzone_CPF_2017.shp')


not_varaible_names=['SUBZONE_N', 'PLN_AREA_N', 'REGION_N','SUBZONE_C', 
                    'PLN_AREA_C', 'REGION_C', 'geometry','stud_lprim',
                    'HDB_AV_1rm','e12k_Over','stud_jcoll','VariableX']
variable_names = sz_cpf.columns[~sz_cpf.columns.isin(not_varaible_names)]
sz_df = sz_cpf[variable_names]


variable_names


formula = 'Ina_CPF_N ~ Age_0to6'


variable_names_X = variable_names.values.tolist()
variable_names_X.remove('Ina_CPF_N')
variable_formula = "+".join(variable_names_X)
variable_formula


formula = 'Ina_CPF_N ~ ' + '+'.join(variable_formula)
formula = 'Ina_CPF_N ~ Age_0to6+Age_20to29+Age_over85+HDB_AV_E+HDB_AV_2rm+House_AV+Condo_AV+EC_AV+Apart_AV+DP+FDW+WP'


sz_df = sm.add_constant(sz_df)
results = ols(formula, sz_df).fit()
results.summary()


# Get points in a grid
l = np.arange(4)
xs, ys = np.meshgrid(l, l)
# Set up store
polys = []
# Generate polygons
for x, y in zip(xs.flatten(), ys.flatten()):
    poly = Polygon([(x, y), (x+1, y), (x+1, y+1), (x, y+1)])
    polys.append(poly)
# Convert to GeoSeries
polys = gpd.GeoSeries(polys)
gdf = gpd.GeoDataFrame({'geometry': polys, 
                        'id': ['P-%s'%str(i).zfill(2) for i in range(len(polys))]})
gdf


ax = gdf.plot(facecolor='w', edgecolor='k')
[plt.text(x, y, t, 
          verticalalignment='center',
          horizontalalignment='center') for x, y, t in zip(
         [p.centroid.x-.25 for p in polys],
         [p.centroid.y-.25 for p in polys],
         [i for i in gdf['id']])]
ax.set_axis_off()
plt.show()


# do a regular 3x3 lattice and draw it here
w = weights.contiguity.Rook.from_dataframe(gdf)
w.neighbors


w.full()


f,ax = plt.subplots(1,1, subplot_kw=dict(aspect='equal'))
w.plot(gdf, edge_kws=dict(color='r', linestyle=':'), ax =ax)
gdf.plot(facecolor='w', edgecolor='k', ax=ax)
[ax.text(x, y, t, 
          verticalalignment='center',
          horizontalalignment='center') for x, y, t in zip(
         [p.centroid.x-.25 for p in polys],
         [p.centroid.y-.25 for p in polys],
         [i for i in gdf['id']])]
plt.gca().set_axis_off()


pd.DataFrame(*w.full()).astype(int)


w.nonzero


# do a regular 3x3 lattice and draw it here
w = weights.contiguity.Queen.from_dataframe(gdf)
w.neighbors


f,ax = plt.subplots(1,1, subplot_kw=dict(aspect='equal'))
w.plot(gdf, edge_kws=dict(color='r', linestyle=':'), ax =ax)
gdf.plot(facecolor='w', edgecolor='k', ax=ax)
[ax.text(x, y, t, 
          verticalalignment='center',
          horizontalalignment='center') for x, y, t in zip(
         [p.centroid.x-.25 for p in polys],
         [p.centroid.y-.25 for p in polys],
         [i for i in gdf['id']])]
plt.gca().set_axis_off()


w.weights


w.cardinalities


w.histogram


type(w.cardinalities)


pd.Series(w.cardinalities).plot.hist(color='k');


w.s0


w.pct_nonzero


w.n


sz = gpd.read_file('Data/MP14_Subzone_SE_2017.shp')
wq = weights.contiguity.Queen.from_dataframe(sz)


len(wq.islands)


ax = sz.plot(edgecolor='k', facecolor='w',figsize=(10,10))
wq.plot(sz, ax=ax, 
        edge_kws=dict(color='r', linestyle=':', linewidth=1),
        node_kws=dict(marker=''))
# ax.set_axis_off()


ax = sz.plot(edgecolor='k', facecolor='w',figsize=(10,10))
wq.plot(sz, ax=ax, 
        edge_kws=dict(color='r', linestyle=':', linewidth=1),
        node_kws=dict(marker=''))
ax.set_axis_off()
ax.axis([20000,  30000, 35000, 40000])


# !pip install folium


import folium


mapa = folium.Map(width=600, height=400, zoom_start=12, detectRetina=True,
            max_zoom=18,
            min_zoom=11,
              location=[1.3, 103.8], tiles='https://maps-{s}.onemap.sg/v3/Default/{z}/{x}/{y}.png',
                 attr= '<img src="https://www.onemap.gov.sg/docs/maps/images/oneMap64-01.png" style="height:20px;width:20px;"/> OneMap | Map data &copy; contributors, <a href="http://SLA.gov.sg">Singapore Land Authority</a>')


mapa


sz.columns


sz_4326 = sz.to_crs(4326)
for _, r in sz_4326.iterrows():
    sim_geo = gpd.GeoSeries(r['geometry'])
#     sim_geo = gpd.GeoSeries(r['geometry']).simplify(tolerance=0.001)
    geo_j = sim_geo.to_json()
    geo_j = folium.GeoJson(data=geo_j,
                           style_function=lambda x: {'fillColor': 'orange'})
    folium.Popup(r['SUBZONE_N']).add_to(geo_j)
    geo_j.add_to(mapa)
mapa


print(wq.n)
print(wq.pct_nonzero)


s = pd.Series(wq.cardinalities)


s.unique().shape


s.plot.hist(bins=s.unique().shape[0]);


wr = weights.contiguity.Rook.from_dataframe(sz)
print(wr.pct_nonzero)
s = pd.Series(wr.cardinalities)
s.plot.hist(bins=s.unique().shape[0]);


wk4 = weights.distance.KNN.from_dataframe(sz, k=4)


wk4.islands


wk4.neighbors


wk4.histogram


w_kernel = weights.distance.Kernel.from_dataframe(sz)


w_kernel.function


w_kernel.bandwidth[0:5]


sz.describe()


sz_central = sz.query("REGION_N == 'CENTRAL REGION'")
ax = sz_central.plot(facecolor='w', edgecolor='k',figsize=(10,10))
sz_central.head(40).centroid.plot(color='r', ax=ax)
ax.set_axis_off()


w_adaptive = weights.distance.Kernel.from_dataframe(sz_central, fixed=False, k=15)
w_adaptive.bandwidth


full_matrix, ids = w_adaptive.full() 


full_matrix[1]


f,ax = plt.subplots(1,2,figsize=(12,6), subplot_kw=dict(aspect='equal'))
sz_central.assign(weight_0 = full_matrix[0]).plot("weight_0", cmap='plasma', ax=ax[0])
sz_central.assign(weight_15 = full_matrix[101]).plot("weight_15", cmap='plasma', ax=ax[1])
ax[0].set_title("Kernel centered on first subzone")
ax[1].set_title("Kernel centered on 100th subzone")
[ax_.set_axis_off() for ax_ in ax]


w_kernel.pct_nonzero


w_bdb = weights.distance.DistanceBand.from_dataframe(sz, 5000, binary=True)


w_hy = weights.distance.DistanceBand.from_dataframe(sz, 5000, binary=False)


w_hy.weights


disconnected_subzone = sz.iloc[[26]] # wq has three isolated areas 26, 263, 289


wq[26]


wk1 = weights.distance.KNN.from_dataframe(sz, k=1)


pd.Series(wk1.cardinalities).unique()


wk1.neighbors[26]


neighbors = wq.neighbors.copy()


neighbors[26].append(27)
neighbors[27].append(26)


wk1.neighbors[263]


wk1.neighbors[289]


neighbors[263].append(291)
neighbors[291].append(263)
neighbors[289].append(308)
neighbors[308].append(289)


wq_new = weights.W(neighbors)


wq_new.islands


w_fixed_sets = weights.set_operations.w_union(wq, wk1)


sz.columns


sz[['SUBZONE_N', 'PLN_AREA_N', 'REGION_N']].head()


w_bl = weights.util.block_weights(sz['PLN_AREA_N'].values, 
                                  ids=sz['SUBZONE_N'].values)


w_bl.weights


f, ax = plt.subplots(1, figsize=(9, 9))
sz.plot(ax=ax)
ax.set_axis_off()
plt.axis('equal')
plt.show()


queen_sz = weights.contiguity.Queen.from_dataframe(sz)
f, ax = plt.subplots(1, figsize=(9, 9))
sz.plot(ax=ax)
queen_sz.plot(sz,edge_kws=dict(linewidth=1.5, color='orangered'), node_kws=dict(marker='*'),  ax=ax, )
ax.set_axis_off()
plt.axis('equal')
plt.show()


ax = sz.plot(column='PLN_AREA_N', categorical=True, cmap='Pastel2')
block_sz = weights.util.block_weights(sz['PLN_AREA_N'].values)
ax.set_axis_off()


f, ax = plt.subplots(1, figsize=(9, 9))
sz.plot(column='PLN_AREA_N', categorical=True, 
        cmap='Pastel2', ax=ax)
block_sz.plot(sz, edge_kws=dict(linewidth=1.5, 
                                color='orangered'), 
                  node_kws=dict(marker='*'), ax=ax)
ax.set_axis_off()
plt.axis('equal')
plt.show()


union_sz = weights.set_operations.w_union(block_sz, queen_sz)

f, ax = plt.subplots(1, figsize=(9, 9))
sz.plot(column='PLN_AREA_N', categorical=True, cmap='Pastel2', ax=ax)
union_sz.plot(sz, edge_kws=dict(linewidth=1.5, 
                                color='orangered'), 
              node_kws=dict(marker='*'), ax=ax)
ax.set_axis_off()
plt.axis('equal')
plt.show()


f, axs = plt.subplots(1, 3, figsize=(18, 6))

# Contiguity
ax = axs[0]
sz.plot(column='PLN_AREA_N', categorical=True, 
        cmap='Pastel2', ax=ax)
queen_sz.plot(sz, edge_kws=dict(linewidth=1.5, color='orangered'), 
              node_kws=dict(marker='*'), ax=ax)
ax.set_axis_off()
ax.set_xlabel('Queen')
ax.axis('equal')

# Block
ax = axs[1]
sz.plot(column='PLN_AREA_N', categorical=True, 
        cmap='Pastel2', ax=ax)
block_sz.plot(sz, edge_kws=dict(linewidth=1.5, color='orangered'), 
              node_kws=dict(marker='*'), ax=ax)
ax.set_axis_off()
ax.set_xlabel('Block weights')
ax.axis('equal')

# Union
ax = axs[2]
sz.plot(column='PLN_AREA_N', categorical=True, 
        cmap='Pastel2', ax=ax)
union_sz.plot(sz, edge_kws=dict(linewidth=1.5, color='orangered'), 
              node_kws=dict(marker='*'), ax=ax)
ax.set_axis_off()
ax.set_xlabel('Queen + Block')
plt.axis('equal')
f.tight_layout()
plt.show()


block_sz.pct_nonzero


queen_sz.pct_nonzero


from pysal.viz import splot
from splot.esda import plot_moran
from pysal.explore import esda
from pysal.lib import weights
from numpy.random import seed


f, ax = plt.subplots(1, 2,figsize=(20, 20))
sz.plot(column='BET20TO24', 
        cmap='viridis',
        scheme='quantiles',
        k=5, 
        edgecolor='white', 
        linewidth=0., 
        alpha=0.75, 
        legend=True,
        legend_kwds={"loc": 2},
        ax=ax[0]
       )

contextily.add_basemap(ax[0], 
                       crs=sz.crs, 
                       source='https://maps-{s}.onemap.sg/v3/Default/{z}/{x}/{y}.png'
                      )

sz.plot(column='e12k_Over', 
        cmap='viridis',
        scheme='quantiles',
        k=5, 
        edgecolor='white', 
        linewidth=0., 
        alpha=0.75, 
        legend=True,
        legend_kwds={"loc": 2},
        ax=ax[1]
       )

contextily.add_basemap(ax[1], 
                       crs=sz.crs, 
                       source='https://maps-{s}.onemap.sg/v3/Default/{z}/{x}/{y}.png'
                      )

ax[0].set_axis_off()
ax[1].set_axis_off()
ax[0].title.set_text('Singapore Population 20 - 24 by Subzone')
ax[1].title.set_text('Singapore income over than 12k by Subzone')


# Generate W from the GeoDataFrame
w = weights.KNN.from_dataframe(sz, k=8)
# Row-standardization
w.transform = 'R'


ax = gdf.plot(facecolor='w', edgecolor='k')
[plt.text(x, y, t, 
          verticalalignment='center',
          horizontalalignment='center') for x, y, t in zip(
         [p.centroid.x-.25 for p in polys],
         [p.centroid.y-.25 for p in polys],
         [i for i in gdf['id']])]
ax.set_axis_off()
plt.show()


gdf['attr']= np.arange(0,16)
gdf


ax = gdf.plot(facecolor='w', edgecolor='k')
[plt.text(x, y, t, 
          verticalalignment='center',
          horizontalalignment='center') for x, y, t in zip(
         [p.centroid.x for p in polys],
         [p.centroid.y for p in polys],
         [i for i in gdf['attr']])]
ax.set_axis_off()
plt.show()


# do a regular 3x3 lattice and draw it here
w = weights.contiguity.Queen.from_dataframe(gdf)
w.neighbors


w.weights


w.to_adjlist()


w.full()


f,ax = plt.subplots(1,1, subplot_kw=dict(aspect='equal'))
w.plot(gdf, edge_kws=dict(color='r', linestyle=':'), ax =ax)
gdf.plot(facecolor='w', edgecolor='k', ax=ax)
[plt.text(x, y, t, 
          verticalalignment='center',
          horizontalalignment='center') for x, y, t in zip(
         [p.centroid.x for p in polys],
         [p.centroid.y for p in polys],
         [i for i in gdf['attr']])]
plt.gca().set_axis_off()


w.full()[0]


spatial_lag_attr= np.matmul(w.full()[0],gdf.filter(['attr']).to_numpy())
spatial_lag_attr


gdf['spatial_lag_attr']=spatial_lag_attr


f,ax = plt.subplots(1,1, subplot_kw=dict(aspect='equal'))
# w.plot(gdf, edge_kws=dict(color='r', linestyle=':'), ax =ax)
gdf.plot(facecolor='w', edgecolor='k', ax=ax)
[plt.text(x, y, t, 
          verticalalignment='center',
          horizontalalignment='center') for x, y, t in zip(
         [p.centroid.x for p in polys],
         [p.centroid.y for p in polys],
         [i for i in gdf['attr']])]

[plt.text(x, y, sl, 
          verticalalignment='center',
          horizontalalignment='center',color="green") for x, y, sl in zip(
         [p.centroid.x -.25 for p in polys],
         [p.centroid.y-.25 for p in polys],
         [i for i in gdf['spatial_lag_attr']])]

plt.gca().set_axis_off()


one spend money on gardon ()
its own house has a price
Dependent value: housing value







# we can do the same with lag_spatial methods
weights.lag_spatial(w,gdf['attr'])



# get the z score (normalize) of each subzone age between 20-24
sz['BET20TO24_std']=(sz['BET20TO24']-sz['BET20TO24'].mean())/sz['BET20TO24'].std()

# get spatial lag of each subzone 
# see wq_new defined above
sz['BET20TO24_lag'] =weights.lag_spatial(wq_new,sz['BET20TO24'])

# get the z score (normalize) of each subzone total residents
sz['BET20TO24_lag_std']=(sz['BET20TO24_lag']-sz['BET20TO24_lag'].mean())/sz['BET20TO24_lag'].std()


f, ax = plt.subplots(1, figsize=(6, 6))
sb.regplot(x='BET20TO24_std', y='BET20TO24_lag_std', 
                ci=None, data=sz, line_kws={'color':'r'})
ax.axvline(0, c='k', alpha=0.5)
ax.axhline(0, c='k', alpha=0.5)
ax.set_title('Moran Plot - TOTALRES')
plt.show()


type(sz['BET20TO24'])


moran = esda.moran.Moran(sz['BET20TO24'], wq_new)


moran.I


sz.plot('BET20TO24',figsize=(12,6),legend=True)


sz['BET20TO24']


moran.p_sim


# plot_moran(moran)


geary = esda.geary.Geary(sz['BET20TO24'], wq)


geary.C


geary.p_sim


pts = sz.centroid
xys = pd.DataFrame({'X': pts.x, 'Y': pts.y})
min_thr = weights.util.min_threshold_distance(xys)
min_thr


pts.plot()


w_sz = weights.DistanceBand.from_dataframe(sz, min_thr)


gao = esda.getisord.G(sz['BET20TO24'], w_sz)


print("Getis & Ord G: %.3f | Pseudo P-value: %.3f"%(gao.G, gao.p_sim))


sz.columns


# Setup the figure and axis
f, ax = plt.subplots(1, figsize=(6, 6))

# Plot values
sb.regplot(x='BET20TO24_std', y='BET20TO24_lag_std', data=sz, ci=None)
# Add vertical and horizontal lines
plt.axvline(0, c='k', alpha=0.5)
plt.axhline(0, c='k', alpha=0.5)
# Add text labels for each quadrant
plt.text(1, 1.5, "HH", fontsize=25)
plt.text(1, -1.5, "HL", fontsize=25)
plt.text(-1.5, 1.5, "LH", fontsize=25)
plt.text(-1.5, -1.5, "LL", fontsize=25)
# Display
plt.show()


# Generate W from the GeoDataFrame
w = weights.distance.KNN.from_dataframe(sz, k=8)
# Row-standardization
w.transform = 'R'


lisa = esda.moran.Moran_Local(sz['BET20TO24'], w)


sb.distplot(lisa.Is)


f, ax = plt.subplots(1, figsize=(9,9))
sz['Is'] = lisa.Is
sz.plot(column='Is', cmap='viridis', scheme='quantiles',
        k=5, edgecolor='white', linewidth=0.1, alpha=0.75, legend=True,ax=ax);

contextily.add_basemap(ax, 
                       crs=sz.crs, 
                       source='https://maps-{s}.onemap.sg/v3/Default/{z}/{x}/{y}.png'
                      )
ax.set_axis_off()


from matplotlib import colors


# Set up figure and axes
f, axs = plt.subplots(nrows=2, ncols=2, figsize=(24, 12))
# Make the axes accessible with single indexing
axs = axs.flatten()

                    # Subplot 1 #
ax = axs[0]
sz.plot(column='Is', cmap='viridis', scheme='quantiles',
        k=5, edgecolor='white', linewidth=0.1, alpha=0.75, legend=True, ax=ax)
ax.set_aspect('equal')
ax.set_axis_off()

                    # Subplot 2 #
ax = axs[1]
q_labels = ['Q1', 'Q2', 'Q3', 'Q4']
labels = [q_labels[i-1] for i in lisa.q]
hmap = colors.ListedColormap([ 'red', 'lightblue', 'blue', 'pink'])
sz.assign(cl=labels).plot(column='cl', categorical=True, \
        k=2, cmap=hmap, linewidth=0.1, ax=ax, \
        edgecolor='white', legend=True)

ax.set_aspect('equal')
ax.set_axis_off()

                    # Subplot 3 #

ax = axs[2]
sig = 1 * (lisa.p_sim < 0.05)
hmap = colors.ListedColormap(['grey','black'])
labels = ['non-sig.', 'significant'] 
labels = [labels[i] for i in sig]
sz.assign(cl=labels).plot(column='cl', categorical=True, \
        k=2, cmap=hmap, linewidth=0.1, ax=ax, \
        edgecolor='white', legend=True)

ax.set_aspect('equal')
ax.set_axis_off()
                            
                    # Subplot 4 #
ax = axs[3]
hotspot = 1 * (sig * lisa.q==1)
coldspot = 3 * (sig * lisa.q==3)
doughnut = 2 * (sig * lisa.q==2)
diamond = 4 * (sig * lisa.q==4)
spots = hotspot + coldspot + doughnut + diamond
spot_labels = [ '0 ns', '1 hot spot', '2 doughnut', '3 cold spot', '4 diamond']
labels = [spot_labels[i] for i in spots]
hmap = colors.ListedColormap([ 'grey', 'red', 'lightblue', 'blue', 'pink'])


sz.assign(cl=labels).plot(column='cl', categorical=True, \
        k=2, cmap=hmap, linewidth=0.1, ax=ax, \
        edgecolor='white', legend=True)

ax.set_aspect('equal')
ax.set_axis_off()


# Display the figure
plt.show()


lisa.q[:10]


counts = [(j,(lisa.q==j).sum()) for j in range(1,5)]
counts


sig = 1 * (lisa.p_sim < 0.05)
sz['p-sim'] = lisa.p_sim
sz['sig'] = sig
sz[['sig','p-sim']].head()


sz[['sig','p-sim']].tail()


hotspot = 1 * (sig * lisa.q==1)
coldspot = 3 * (sig * lisa.q==3)
doughnut = 2 * (sig * lisa.q==2)
diamond = 4 * (sig * lisa.q==4)
spots = hotspot + coldspot + doughnut + diamond
spot_labels = [ '0 ns', '1 hot spot', '2 doughnut', '3 cold spot', '4 diamond']


sz['labels'] = labels
[(spot_label, (sz['labels']==spot_label).sum()) for spot_label in spot_labels]


sz_cpf = gpd.read_file('Data/MP14_Subzone_CPF_2017.shp')


not_varaible_names=['SUBZONE_N', 'PLN_AREA_N', 'REGION_N','SUBZONE_C', 
                    'PLN_AREA_C', 'REGION_C', 'geometry','stud_lprim',
                    'HDB_AV_1rm','e12k_Over','stud_jcoll','VariableX']
variable_names = sz_cpf.columns[~sz_cpf.columns.isin(not_varaible_names)]
sz_df = sz_cpf[variable_names]


variable_names_X = variable_names.values.tolist()
variable_names_X.remove('Ina_CPF_N')
# variable_formula = "+".join(variable_names_X)
# variable_formula


m_ols = spreg.OLS(
    sz_df[['Ina_CPF_N']].values, 
    sz_df[variable_names_X].values,
    name_y='Ina_CPF_N', 
    name_x=variable_names_X
)
print(m_ols.summary)


w = weights.contiguity.Queen.from_dataframe(sz_cpf)


w.islands


knn = weights.KNN.from_dataframe(sz_cpf, k=4)


neighbors = w.neighbors.copy()


[neighbors[i].extend(knn.neighbors[i]) for i in w.islands]


w_new = weights.W(neighbors)


w_new.transform = 'R'


lag_residual = weights.spatial_lag.lag_spatial(w_new, m_ols.u)
ax = sb.regplot(
    m_ols.u.flatten(), 
    lag_residual.flatten(), 
    line_kws=dict(color='orangered'),
    ci=None
)
ax.set_xlabel('Model Residuals - $u$')
ax.set_ylabel('Spatial Lag of Model Residuals - $W u$')


sz_df = sz_df.assign(REGION_N = sz_cpf['REGION_N'])


sz_df


f = 'Ina_CPF_N ~ ' + ' + '.join(variable_names_X) + ' + REGION_N - 1'
print(f)


m_sm_regimes = ols(f, data=sz_df).fit()
print(m_sm_regimes.summary2())


# PySAL implementation
m_OLS_Regimes = spreg.OLS_Regimes(
    sz_df[['Ina_CPF_N']].values, 
    sz_df[variable_names_X].values,
    sz_df['REGION_N'].tolist(),
    constant_regi='many',
    cols2regi=[False]*len(variable_names_X),
    regime_err_sep=False,
    name_y='Ina_CPF_N', 
    name_x=variable_names_X
)
print(m_OLS_Regimes.summary)


m_GM_Lag = spreg.GM_Lag(
    sz_df[['Ina_CPF_N']].values, 
    sz_df[variable_names_X].values,
    w=w_new,
    name_y='Ina_CPF_N',
    name_x=variable_names_X
)
print(m_GM_Lag.summary)


sb.scatterplot(x=list(range(0,321)),y=m_ols.u.flatten())
sb.scatterplot(x=list(range(0,321)),y=m_GM_Lag.u.flatten())


dataset


dataset_panel= dataset.loc[:,['Gender','Height','Weight']].copy()


dataset_panel=dataset_panel.rename(columns={'Height':'Height_Age_18','Weight':'Weight_Age_18'})


dataset_panel = dataset_panel.assign(Height_Age_20 = dataset_panel['Height_Age_18']+np.random.normal(2,0.2,len(dataset_panel)),
                    Weight_Age_20 = dataset_panel['Weight_Age_18']+ 0.5 * np.random.normal(2,0.2,len(dataset_panel)))
dataset_panel


from statsmodels.stats.anova import AnovaRM


# add subject ID
dataset_panel['Sub_ID']=dataset_panel.index +1


dataset_panel


# wide to long for statsmodel
dataset_panel_long = pd.wide_to_long(dataset_panel, ["Height_Age", "Weight_Age"], i=["Sub_ID","Gender"], j="Age", sep="_").reset_index()
dataset_panel_long


test_df=dataset_panel_long.iloc[np.r_[0:20,10000:10020],:]
test_df


aovrm = AnovaRM(test_df, 'Height_Age', 'Sub_ID', within=['Age'])
res = aovrm.fit()

print(res)


import pykrige.kriging_tools as kt
from pykrige.ok import OrdinaryKriging
from pykrige.uk import UniversalKriging
import matplotlib.pyplot as plt
import seaborn as sb
import gstools as gs


from datetime import datetime
import json
from pandas import json_normalize
import requests
dt_string = "2020-12-01" 

format = "%Y-%m-%d"
dt_object = datetime.strptime(dt_string, format)
dt_object.date()
datelist = pd.date_range(dt_object.date(), periods=3).tolist()

# download 10 days Singapore rainfall data
# for i,dt in enumerate(datelist):
#     print((i+1)*100/len(datelist))
#     response = requests.get('https://api.data.gov.sg/v1/environment/rainfall?date='+dt.strftime("%Y-%m-%d"))
#     print(response.status_code)

#     with open(f'Data/Rainfall_Download/test{i}.json', 'w') as f:
#         json.dump(response.json(), f)

# responses = [requests.get('https://api.data.gov.sg/v1/environment/rainfall?date='+i.strftime("%Y-%m-%d")) for i in datelist]
# [print(i.status_code) for i in responses]

# for i,response in enumerate(responses):
#     with open(f'Data/Rainfall/test{i}.json', 'w') as f:
#         json.dump(response.json(), f)


import os
responses_json =[]
for filename in os.listdir('Data/Rainfall'):
    with open(os.path.join('Data/Rainfall', filename), 'r') as f: # open in readonly mode
        response = json.load(f)
        responses_json.append(response)


# df_dict=responses[0].json() # if use online download
df_dict=responses_json[0] # if read files


df_dict['metadata']['stations']


df_stations = pd.DataFrame(df_dict['metadata']['stations'])


df_stations


df_st= df_stations.drop('location', axis=1).join(pd.DataFrame(df_stations.location.values.tolist()))
df_st


# uncomment the following line if you use online requests
# df_rainfall = [pd.DataFrame(response.json()['items']).assign(Day_ID=i+1, Time_ID = pd.DataFrame(response.json()['items']).index+1) for i,response in enumerate(responses)]

# uncomment the next line if you use files in rainfall folder
df_rainfall = [pd.DataFrame(response['items']).assign(Day_ID=i+1, Time_ID = pd.DataFrame(response['items']).index+1) for i,response in enumerate(responses_json)]


df_rainfall_all =pd.concat(df_rainfall, axis=0)


df_rainfall_all


df = pd.concat([pd.DataFrame(row.readings).assign(Day_ID=row.Day_ID,Time_ID=row.Time_ID) for index, row in df_rainfall_all.iterrows()]).reset_index()
df


df_agg= df.groupby(['Day_ID','station_id']).sum().drop(['Time_ID','index'],axis=1).reset_index()


df_agg


df_stations


df_agg_for_kriging = df_agg.merge(df_st,left_on='station_id',right_on='device_id')


df_agg_for_kriging


import geopandas as gp


df_rainfall_geoms = gp.points_from_xy(x=df_agg_for_kriging["longitude"],
                                    y=df_agg_for_kriging["latitude"],
                                    crs="epsg:4326"
                                   )


rainfall = gp.GeoDataFrame(df_agg_for_kriging,
                                   geometry=df_rainfall_geoms
                                  )


# ensure that the two layers have the same crs
# here we have to transform the crs instead of set a new
rainfall=rainfall.to_crs("epsg:3414")


sz = gp.read_file('Data/MP14_Subzone_SE_2017.shp')


f, ax = plt.subplots(1, figsize=(9, 9))
sz.plot(ax=ax, legend=False, facecolor="none",edgecolor="k",lw=0.1)
rainfall.plot(ax=ax, column='value', legend=True, scheme='Quantiles', legend_kwds={'fmt':'{:.0f}'}, cmap='Blues', edgecolor="k")
ax.set_title('Singapore Rainfall Data')
plt.axis('equal')
plt.show()


rainfall.dtypes


rainfall_day=rainfall.query('Day_ID == 3')


extent = min_x, max_x, min_y, max_y = [rainfall.geometry.x.min()-1000, rainfall.geometry.x.max()+1000,
                                       rainfall.geometry.y.min()-1000, rainfall.geometry.y.max()+1000]


fig, ax = plt.subplots(figsize=(10,6))

ax.scatter(rainfall.geometry.x, rainfall.geometry.y, c=rainfall.value)
ax.set_aspect(1)
ax.set_xlim(*extent[:2])
ax.set_ylim(*extent[2:])
ax.set_xlabel('Easting [m]')
ax.set_ylabel('Northing [m]')
ax.set_title('Singapore Rainfall(mm)')
ax.grid(c='k', alpha=0.2)

plt.show()


gridx, gridy = np.mgrid[min_x:max_x:500, min_y:max_x:500]


plt.figure(figsize=(10,6))
plt.scatter(gridx, gridy, s=10)


from scipy.interpolate import Rbf

# Make an n-dimensional interpolator. 

rbfi = Rbf(rainfall_day.geometry.x, rainfall_day.geometry.y, rainfall_day.value)

# Predict on the regular grid. Line 5.
di = rbfi(gridx, gridy)


mi = np.min(np.hstack([di.ravel(), rainfall_day.value.values]))
ma = np.max(np.hstack([di.ravel(), rainfall_day.value.values]))


plt.figure(figsize=(15,15))
c1 = plt.imshow(di.T, origin="lower", extent=extent, vmin=mi, vmax=ma)
c2 = plt.scatter(rainfall_day.geometry.x, rainfall_day.geometry.y, s=60, c=rainfall_day.value, edgecolor='#ffffff66', vmin=mi, vmax=ma)

plt.colorbar(c1, shrink=0.67)
plt.show()


rbfi = Rbf(rainfall_day.geometry.x, rainfall_day.geometry.y, rainfall_day.value, smooth=0.2)
di = rbfi(gridx, gridy)

fig, ax = plt.subplots(figsize=(15,15))
plt.imshow(di.T, origin="lower", extent=extent)
plt.scatter(rainfall_day.geometry.x, rainfall_day.geometry.y, s=2, c='w')
plt.show()



value_hat = rbfi(rainfall_day.geometry.x, rainfall_day.geometry.y)

sb.distplot(value_hat - rainfall_day.value)


points = np.vstack((rainfall_day.geometry.x,rainfall_day.geometry.y)).T


points.shape


from scipy.interpolate import griddata

grid_z0 = griddata(points, rainfall_day.value.values, (gridx, gridy), method='nearest')
grid_z1 = griddata(points, rainfall_day.value.values, (gridx, gridy), method='linear')
grid_z2 = griddata(points, rainfall_day.value.values, (gridx, gridy), method='cubic')


fig, axs = plt.subplots(ncols=3, figsize=(15, 5))

ax = axs[0]
ax.imshow(grid_z0, origin='lower', extent=extent)
ax.scatter(rainfall_day.geometry.x,rainfall_day.geometry.y, s=2, c='w')
ax.set_title('Nearest')

ax = axs[1]
ax.imshow(grid_z1, origin='lower', extent=extent)
ax.scatter(rainfall_day.geometry.x,rainfall_day.geometry.y, s=2, c='w')
ax.set_title('Linear')

ax = axs[2]
ax.imshow(grid_z2, origin='lower', extent=extent)
ax.scatter(rainfall_day.geometry.x,rainfall_day.geometry.y, s=2, c='w')
ax.set_title('Cubic')

plt.show()


from sklearn.gaussian_process.kernels import RBF

kernel = RBF(length_scale=1000)


from sklearn.gaussian_process import GaussianProcessRegressor

gp = GaussianProcessRegressor(normalize_y=True,
                              alpha=0.1,  # Larger values imply more noise in the input data.
                              kernel=kernel)

gp.fit(points, rainfall_day.value.values)


X_grid = np.stack([gridx.ravel(), gridy.ravel()]).T


y_grid = gp.predict(X_grid).reshape(gridx.shape)


# Compute min and max of all the data:
mi = np.min(np.hstack([y_grid.ravel(), rainfall_day.value.values]))
ma = np.max(np.hstack([y_grid.ravel(), rainfall_day.value.values]))

# Plot it all.
plt.figure(figsize=(15,15))
im = plt.imshow(y_grid.T, origin='lower', extent=extent, vmin=mi, vmax=ma)
pts = plt.scatter(rainfall_day.geometry.x, rainfall_day.geometry.y, c=rainfall_day.value, s=80, edgecolor='#ffffff66', vmin=mi, vmax=ma)
plt.colorbar(im, shrink=0.67)
plt.show()


value_hat = gp.predict(points)

sb.distplot(value_hat - rainfall_day.value)



